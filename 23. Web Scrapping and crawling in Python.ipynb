{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "### Web Scrapping in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'But soft what light through yonder window breaks'\n",
      "b'It is the east and Juliet is the sun'\n",
      "b'Arise fair sun and kill the envious moon'\n",
      "b'Who is already sick and pale with grief'\n"
     ]
    }
   ],
   "source": [
    "from urllib import *\n",
    "fhand = request.urlopen('http://www.py4inf.com/code/romeo.txt')\n",
    "for line in fhand:\n",
    "    print(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{b'But': 1, b'soft': 1, b'what': 1, b'light': 1, b'through': 1, b'yonder': 1, b'window': 1, b'breaks': 1, b'It': 1, b'is': 3, b'the': 3, b'east': 1, b'and': 3, b'Juliet': 1, b'sun': 2, b'Arise': 1, b'fair': 1, b'kill': 1, b'envious': 1, b'moon': 1, b'Who': 1, b'already': 1, b'sick': 1, b'pale': 1, b'with': 1, b'grief': 1}\n"
     ]
    }
   ],
   "source": [
    "fhand = request.urlopen('http://www.py4inf.com/code/romeo.txt')\n",
    "counts = dict()\n",
    "for line in fhand:\n",
    "    words = line.split()\n",
    "    for word in words:\n",
    "        counts[word] = counts.get(word,0)+1\n",
    "\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<h1>The First Page</h1>'\n",
      "b'<p>'\n",
      "b'If you like, you can switch to the'\n",
      "b'<a href=\"http://www.dr-chuck.com/page2.htm\">'\n",
      "b'Second Page</a>.'\n",
      "b'</p>'\n"
     ]
    }
   ],
   "source": [
    "from urllib import *\n",
    "fhand = request.urlopen('http://www.dr-chuck.com/page1.htm')\n",
    "for line in fhand:\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter - http://www.dr-chuck.com/page1.htm\n",
      "http://www.dr-chuck.com/page2.htm\n"
     ]
    }
   ],
   "source": [
    "# Understand html data using BeautifulSoup\n",
    "from urllib import *\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = input('Enter - ')\n",
    "\n",
    "html = request.urlopen(url).read()\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "# Retrieve a list of the anchor tags\n",
    "# Each tag is like a dictionary of HTML attributes\n",
    "\n",
    "tags = soup('a')\n",
    "\n",
    "for tag in tags:\n",
    "    print(tag.get('href', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
